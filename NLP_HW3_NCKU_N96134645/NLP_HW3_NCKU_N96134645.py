# -*- coding: utf-8 -*-
"""NLP_HW3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P9ypCoPPyazGxwpVNSZ6mR0IF_eKeqh9
"""

!pip install datasets==2.21.0
!pip install torchmetrics

import transformers as T
from datasets import load_dataset
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from tqdm import tqdm
from torchmetrics import SpearmanCorrCoef, Accuracy, F1Score

device = "cuda:0" if torch.cuda.is_available() else "cpu"

import os

# 檢查是否存在 saved_models 資料夾，如果不存在則建立
os.makedirs('./saved_models', exist_ok=True)

# 有些中文的標點符號在tokenizer編碼以後會變成[UNK]，所以將其換成英文標點
token_replacement = [
    ["：" , ":"],
    ["，" , ","],
    ["“" , "\""],
    ["”" , "\""],
    ["？" , "?"],
    ["……" , "..."],
    ["！" , "!"]
]

class SemevalDataset(Dataset):
    def __init__(self, split="train") -> None:
        super().__init__()
        assert split in ["train", "validation"]
        self.data = load_dataset(
            "sem_eval_2014_task_1", split=split, cache_dir="./cache/"
        ).to_list()

    def __getitem__(self, index):
        d = self.data[index]
        # 把中文標點替換掉
        for k in ["premise", "hypothesis"]:
            for tok in token_replacement:
                d[k] = d[k].replace(tok[0], tok[1])
        return d

    def __len__(self):
        return len(self.data)

data_sample = SemevalDataset(split="train").data[:3]
print(f"Dataset example: \n{data_sample[0]} \n{data_sample[1]} \n{data_sample[2]}")

model_name = "bert-base-cased"
tokenizer = T.BertTokenizer.from_pretrained("google-bert/bert-base-cased", cache_dir="./cache/")

# Define the hyperparameters
lr = 3e-5
epochs = 5
train_batch_size = 8
validation_batch_size = 8

# TODO1: Create batched data for DataLoader
# `collate_fn` is a function that defines how the data batch should be packed.
# This function will be called in the DataLoader to pack the data batch.

def collate_fn(batch):
    # TODO1-1: Implement the collate_fn function
    # Write your code here
    # The input parameter is a data batch (tuple), and this function packs it into tensors.

    ## ⬇️由chatgpt提供寫法⬇️ ##
    input_ids = []
    attention_mask = []
    relatedness_score = []
    entailment_judgment = []

    for item in batch:
        # 取出 premise 和 hypothesis
        premise = item['premise']
        hypothesis = item['hypothesis']

        # 使用 tokenizer 將 premise 和 hypothesis 拼接並編碼
        encoding = tokenizer(
            premise,
            hypothesis,
            padding='max_length',  # 可以選擇 'max_length' 來補齊長度，或 'longest' 等
            truncation=True,        # 長度過長時進行截斷
            return_tensors='pt'     # 返回 PyTorch tensor 格式
        )

        input_ids.append(encoding['input_ids'].squeeze(0))  # 移除 batch 維度
        attention_mask.append(encoding['attention_mask'].squeeze(0))

        # 相關性得分和推理判斷標籤直接提取
        relatedness_score.append(item['relatedness_score'])
        entailment_judgment.append(item['entailment_judgment'])

    # 將列表轉換為 tensor
    input_ids = torch.stack(input_ids, dim=0)
    attention_mask = torch.stack(attention_mask, dim=0)
    relatedness_score = torch.tensor(relatedness_score, dtype=torch.float)
    entailment_judgment = torch.tensor(entailment_judgment, dtype=torch.long)

    return {
        "input_ids": input_ids,
        "attention_mask": attention_mask,
        "relatedness_score": relatedness_score,
        "entailment_judgment": entailment_judgment,
    }
    ## ⬆️由chatgpt提供寫法⬆️ ##


# TODO1-2: Define your DataLoader
dl_train = DataLoader(SemevalDataset(split="train"), batch_size=train_batch_size, collate_fn=collate_fn, shuffle=True)
dl_validation = DataLoader(SemevalDataset(split="validation"), batch_size=validation_batch_size, collate_fn=collate_fn)

print(next(iter(dl_train)))

# TODO2: Construct your model
class MultiLabelModel(torch.nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Write your code here
        # Define what modules you will use in the model

        ## ⬇️由chatgpt提供寫法⬇️ ##
        self.encoder = T.AutoModel.from_pretrained(model_name)

        # 增加多層線性變換
        hidden_size = self.encoder.config.hidden_size
        intermediate_dim = 512  # 中間層維度

        # Relatedness head (Regression)
        self.relatedness_head = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, intermediate_dim),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),  # 防止過擬合
            torch.nn.Linear(intermediate_dim, 1),
        )

        # Entailment head (Classification)
        self.entailment_head = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, intermediate_dim),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(intermediate_dim, 3),
        )

    def forward(self, **kwargs):
        # Write your code here
        # Forward pass
        input_ids = kwargs.get('input_ids')
        attention_mask = kwargs.get('attention_mask')

        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output  # Use pooled output for classification/regression tasks

        # Task-specific outputs
        relatedness_score = self.relatedness_head(pooled_output).squeeze(-1)  # Regression output
        entailment_judgment = self.entailment_head(pooled_output)        # Classification logits

        return {
            "relatedness_score": relatedness_score,
            "entailment_judgment": entailment_judgment
        }
        ## ⬆️由chatgpt提供寫法⬆️ ##

model = MultiLabelModel().to(device)

# TODO3: Define your optimizer and loss function

# TODO3-1: Define your Optimizer

## ⬇️由chatgpt提供寫法⬇️ ##

optimizer = AdamW([
    {"params": model.encoder.parameters(), "lr": 1e-5},  # Lower learning rate for pre-trained model
    {"params": model.relatedness_head.parameters(), "lr": 1e-4},
    {"params": model.entailment_head.parameters(), "lr": 1e-4}
])

# TODO3-2: Define your loss functions (you should have two)
# Write your code here
regression_loss_fn = torch.nn.MSELoss()         # For `relatedness_score` (regression)
classification_loss_fn = torch.nn.CrossEntropyLoss()  # For `entailment_judgment` (classification)

## ⬆️由chatgpt提供寫法⬆️ ##

# scoring functions
spc = SpearmanCorrCoef()
acc = Accuracy(task="multiclass", num_classes=3)
f1 = F1Score(task="multiclass", num_classes=3, average='macro')

initial_weight = 0.8

for ep in range(epochs):
    # Dynamic weight tuning
    relatedness_weight = initial_weight - ep * 0.1  # Reduce relatedness weight per epoch
    entailment_weight = 1.0 - relatedness_weight    # Ensure weights sum to 1

    pbar = tqdm(dl_train)
    pbar.set_description(f"Training epoch [{ep+1}/{epochs}]")
    model.train()

    total_loss = 0

    # TODO4: Write the training loop
    for batch in pbar:
    # Write your code here
    # train your model
    # clear gradient
      optimizer.zero_grad()

      ## ⬇️由chatgpt提供寫法⬇️ ##

      # forward pass
      inputs = {k: v.to(device) for k, v in batch.items() if k in ["input_ids", "attention_mask"]}
      outputs = model(**inputs)

      # compute loss
      relatedness_loss = regression_loss_fn(outputs["relatedness_score"], batch["relatedness_score"].to(device))
      entailment_loss = classification_loss_fn(outputs["entailment_judgment"], batch["entailment_judgment"].to(device))

      loss = (relatedness_weight * relatedness_loss) + (entailment_weight * entailment_loss)

      total_loss += loss.item()

      # back-propagation
      loss.backward()

      # model optimization
      optimizer.step()

      pbar.set_postfix({"Loss": total_loss / (pbar.n + 1)})


    pbar = tqdm(dl_validation)
    pbar.set_description(f"Validation epoch [{ep+1}/{epochs}]")
    model.eval()
    # TODO5: Write the evaluation loop
    # Write your code here
    # Evaluate your model
    with torch.no_grad():
      total_relatedness_score, total_entailment_preds, total_entailment_labels = [], [], []

      for batch in pbar:
        # Forward pass
        inputs = {k: v.to(device) for k, v in batch.items() if k in ["input_ids", "attention_mask"]}
        outputs = model(**inputs)

        # Store predictions and labels for each task
        relatedness_preds = outputs["relatedness_score"].cpu()
        entailment_preds = outputs["entailment_judgment"].argmax(dim=1).cpu()

        total_relatedness_score.extend(zip(relatedness_preds, batch["relatedness_score"]))
        total_entailment_preds.extend(entailment_preds)
        total_entailment_labels.extend(batch["entailment_judgment"])

    # Output all the evaluation scores (SpearmanCorrCoef, Accuracy, F1Score)
      spc_score = spc(torch.tensor([p for p, _ in total_relatedness_score]),
                        torch.tensor([t for _, t in total_relatedness_score]))
      acc_score = acc(torch.tensor(total_entailment_preds), torch.tensor(total_entailment_labels))
      f1_score = f1(torch.tensor(total_entailment_preds), torch.tensor(total_entailment_labels))

      # Output metrics
      print(f"Spearman Corr: {spc_score:.4f}, Accuracy: {acc_score:.4f}, F1 Score: {f1_score:.4f}")

    ## ⬆️由chatgpt提供寫法⬆️ ##

    torch.save(model, f'./saved_models/ep{ep}.ckpt')

## ⬇️由chatgpt提供寫法⬇️ ##

# Error analysis after calculating metrics
error_analysis = {"predicted": [], "true": []}

# Collect misclassified examples
for pred, true in zip(total_entailment_preds, total_entailment_labels):
    if pred != true:
        error_analysis["predicted"].append(pred.item())
        error_analysis["true"].append(true.item())

# Analyze misclassification breakdown
from collections import Counter
error_counts = Counter(zip(error_analysis["predicted"], error_analysis["true"]))
print("Error breakdown (predicted -> true):", error_counts)

# Optionally, add a confusion matrix for visualization
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

ConfusionMatrixDisplay.from_predictions(total_entailment_labels, total_entailment_preds, display_labels=["Neutral", "Entailment", "Contradiction"])
plt.title("Confusion Matrix for Entailment Judgment")
plt.show()

## ⬆️由chatgpt提供寫法⬆️

!nvidia-smi

!pip freeze | grep -E 'torch|transformers|datasets|tqdm|torchmetrics' > requirements.txt

"""For test set predictions, you can write perform evaluation simlar to #TODO5."""